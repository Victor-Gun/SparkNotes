#《Hadoop权威指南》note1-初识Hadoop
_整理：leotse_

### 大数据胜于好算法
对于某些应用，不论算法有多牛，基于小数据的推荐效果往往都不如基于大量可用数据的一般算法的推荐效果。

**Note**：巧妇难为无米之炊。例如音乐推荐，如果收集了你某两三次的歌曲播放习惯，就开始对你的音乐偏好进行归类和打标签，然后给你推荐音乐，这是不怎么令人信服的。

### Hadoop的优势
1.Hadoop提供了一个可靠的共享存储和分析系统。HDFS实现数据的存储，而MapReduce实现对数据的分析和处理。虽然Hadoop还有诸如Hive、Sqoop之类的其他组件，但HDFS和MR是它的核心价值。

**Note**：比如Hive和HBase都是基于HDFS的数据库（数据仓库）；Sqoop是实现了结构化数据存储和HDFS之间的高速数据传输，Oozie用于调度Hadoop作业。由此可见，理解HDFS和MR是掌握Hadoop的必要前提。

2.为什么不能用数据库来对大量硬盘上的大规模数据进行批量分析呢？我们为什么需要MR？  
这两个问题来源于计算机硬盘的一个发展趋势：寻址时间的提升远远不及传输速率的提升。  
寻址：将磁头移动到特定磁盘位置进行读写的过程。它是导致磁盘操作延迟的主要原因；  
传输速率取决于硬盘的带宽（单位时间可以传输的数据总量）；
数据库的读写操作相对比较频繁，数据量过大的时候进行数据的更新，B树的效率就明显落后于MR。  

另一方面，数据库处理的数据一般是结构化的，而MR对半结构化和非结构化的数据非常有效。

**Note**：我们在这里看到，MR相对于数据库的优势也只有在特定情况下才能显示出来。而数据量不大、或者数据更新频繁等情况，MR的劣势也会暴露无遗。我们只有在正确了解Hadoop的适用场景以及我们业务的实际需求，才能准确判断是否应该引入Hadoop。

3.相对于网格计算，MR的优势在于**数据本地化**（MR尽量在计算节点上存储数据，以实现数据的本地快速访问）。**数据本地化**也是MR的核心特征。因为网络带宽是数据中心环境中最珍贵的资源。

### Hadoop生态系统
Hadoop的主要成员有：  
**Common**：用于分布式文件系统和通用IO的一系列组件和接口；  
**Avro**：用于支持高效、跨语言的RPC和持久化数据存储的一种序列化系统；  
**MapReduce**：分布式数据处理模型和执行环境；  
**HDFS**：分布式文件系统；  
**Pig**：数据流语言和运行环境，用以探究非常庞大的数据集。Pig运行在HDFS和MR集群上；  
**Hive**：一种分布式的、按列存储的数据仓库。Hive管理HDFS中存储的数据，并提供了基于SQL的查询语言（_由运行时引擎翻译为MR作业_）用以查询数据；  
**HBase**：一种分布式的、按列存储的数据库。HBase使用HDFS作为底层存储，同时支持MR计算和点查询（随机读取）；  
**ZooKeeper**：一种分布式的、可用性高的协调服务。提供分布式锁之类的基本服务用于构建分布式应用；  
**Sqoop**：用于在结构化数据存储和HDFS之间进行高效的批量数据传输；  
**Oozie**：用于运行和调度Hadoop作业；

**Note**：Hadoop家族很庞大，生态系统也很完善。但是这些家族成员有多么复杂，其都是基于或围绕HDFS和MR展开。因此我们学习Hadoop最重要的就是要深刻理解HDFS和MR。

### Hadoop的发行版本
应该使用哪个版本的Hadoop呢？这个问题对很对初学者和部署使用人员来说都不陌生，我们选择Hadoop的版本首先取决于我们需要使用哪些特性。  
首先，1.x的发行版本是0.20发行版本的延续，并且包含当前最稳定的Hadoop发行版本。几乎所有集群运行的都是这些发行版本或扩展版本；  
0.22和2.x发行版本系列目前还不是非常稳定，它们有以下新特性：  
1）在新的YARN（Yet Another Resource Negotiator）系统上构建了一个新的环境，称为MapReduce 2，YARN是一个通用的资源管理器；  
2）HDFS联邦管理（不同的地方叫法不一）：它将HDFS的命名空间分散到多个Namenode中以支持包含大规模数据文件的集群；  
3）HDFS的高可用性：针对系统崩溃而启用备用的Namenode来避免单点故障；

**Note**：我们常常会看到Apache Hadoop和CDH两种版本的Hadoop，那么这两种版本有什么区别呢？我们来看[董的博客](http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/)上的一段话： 

Apache Hadoop版本分为两代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0。第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则NameNode HA等新的重大特性。第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性。  
Apache当前的版本管理是比较混乱的，各种版本层出不穷，让很多初学者不知所措，相比之下，Cloudera公司的Hadoop版本管理的要很多。  
我们知道，Hadoop遵从Apache开源协议，用户可以免费地任意使用和修改Hadoop，也正因此，市面上出现了很多Hadoop版本，其中比较出名的一是Cloudera公司的发行版，我们将该版本称为CDH（Cloudera Distribution Hadoop）。截至目前为止，CDH共有4个版本，其中，前两个已经不再更新，最近的两个，分别是CDH3（在Apache Hadoop 0.20.2版本基础上演化而来的）和CDH4在Apache Hadoop 2.0.0版本基础上演化而来的），分别对应Apache的Hadoop 1.0和Hadoop 2.0，它们每隔一段时间便会更新一次。


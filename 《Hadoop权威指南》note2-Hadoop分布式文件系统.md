#《Hadoop权威指南》note2-Hadoop分布式文件系统
_整理：leotse_

### 分布式文件系统
管理网络上跨平台多台计算机存储的文件系统。

**Note**：非常另类的定义。这是迄今为止本人见过最言简意赅的DFS定义。

### HDFS的设计

1.HDFS以流式数据访问模式来存储超大文件，运行于商用硬件集群上。

**Note**：这里的“超大文件”是指数百MB，数百GB以至于数百TB大小的文件；在选择DFS的时候，我们需要根据我们实际的文件大小来加以判断，比如淘宝开源的TFS适用于海量小文件（<1MB）的场景。HDFS一开始设计的时候就是为了存储大文件，而且是超大文件；  
流式数据是指：在HDFS上进行文件相关分析操作，一般都会读取数据集的大部分或者全部，即读取的文件非常大，因此读第一条记录的延迟就显得不那么重要。

2.HDFS不适用低延迟的数据访问。HDFS是为高吞吐应用设计和优化的，因此会损失一部分的时间性能。

3.大量的小文件。Namenode将HDFS的元数据存储在内存中，所以，HDFS集群的存储能力受限于Namenode的内存大小。

**Note**：根据《Hadoop权威指南》作者的介绍，一般情况下，每个文件、目录和数据块的存储信息大约占150 Byte；如果有100w个文件，且每个文件占一个数据块，则需要300MB的内存。  
HDFS的这种设计（事实上，不少文件系统都是这样设计，由中控节点负责管理所有的元数据）遭到一些人的诟病，因为存在单点故障，于是出现了去中心化的分布式文件系统，也出现了不管理元数据的分布式文件系统，比如[FastDFS](https://github.com/leotse90/blogs/blob/master/FastDFS%E6%A6%82%E8%A7%88.md)。

4.HDFS的文件可能只有一个writer，而且写操作总是将数据追加在文件末尾。HDFS当前不支持多个writer的操作，也不支持在文件的任意位置进行修改。

**Note**：不支持多个writer可以保证文件的一致性，防止同时修改某一文件造成冲突。不支持任意位置修改文件可能是因为HDFS会将文件进行分块存储（默认64MB）有关，数据块的重新分配与写入，文件的一致性等等导致任意修改的代价高昂且效率非常低。  

### HDFS的概念

1.**数据块**  
1）每个磁盘都有默认的数据块大小，这是磁盘进行读写的最小单位。文件系统中也存在块的概念，一般是磁盘数据块大小的整数倍。但是这些都是对用户透明的；

2）HDFS中数据块默认大小为64MB，我们称这些分块为chunk，是HDFS的独立存储单元。HDFS中，一个数据块没有写满是不会写另一个数据块的。

3）为什么HDFS的数据块的是64MB？  
这是由于以下两个原因：a.我们在[《Hadoop权威指南》note1-初识Hadoop](https://github.com/leotse90/SparkNotes/blob/master/%E3%80%8AHadoop%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8Bnote1-%E5%88%9D%E8%AF%86Hadoop.md)中了解到，寻址时间对于大数据存储分析非常重要，因此，当块设置得足够大，就能降低寻址时间在整个处理过程（寻址+传输）中的占比，因而，传输一个由多个数据块组成的文件的时间取决于磁盘传输速率；换个说法就是，数据块越大，寻址次数越少！b.既然可以降低寻址时间，那么为什么不设置得更大一点呢？这是因为MR中map任务通常一次只处理一个块中的数据，如果数据块size太大，会减少处理map任务的机器数，从而影响计算效率。

**Note**：吐槽一下，为什么不是48MB，也不是72MB？



未完待续...